# Persona/Greeting Trace + Conflict Map

## 1. Greeting Origin Trace
**Target Phrase:** "Hi there, how can I assist you today" (and variants)
**Finding:** <mark>NOT FOUND</mark> as a literal string in the codebase (backend or frontend).

**Conclusion:**
This greeting is dynamically generated by the LLM during the first turn of conversation, derived from the `life_architect` system prompt and the lack of conversation history.

- **Primary Source:** `z:/Othello/utils/prompts.py` (Line 6)
  - **Prompt:** `life_architect`
  - **Instruction:** "You are Othello, a Personal Goal Architect... Response Style: Conversational and encouraging... Example Tone: Hi! Love the direction."
  - **Effect:** When the user initiates a session without a specific intent, the model defaults to this "helpful assistant" persona, often outputting "Hi there, how can I help?" or similar.

- **Secondary Source (UI Placeholders):**
  - `othello_ui.html`: `<div id="chat-placeholder">Start a conversation</div>`
  - `othello_ui.html`: `<textarea placeholder="Tell Othello what you're working towards...">`

## 2. Prompt Selection Map

### Path A: General Chat Loop
- **Trigger:** `/message` endpoint -> `ArchitectBrain.chat_loop`
- **Prompt Used:** `load_prompt("life_architect")`
- **Result:** Full persona (Warm, supportive, plain text).

### Path B: Strict Planning Mode (Goal Creation)
- **Trigger:** `ArchitectBrain.generate_goal_plan`
- **Prompt Used:** `load_prompt("life_architect")` + **Appended Strings**
- **Construction:**
  ```python
  system_prompt = load_prompt("life_architect")
  system_prompt += (
      "\n\n=== STRICT PLANNING MODE ===\n"
      "You are in XML-ONLY output mode... NO prose."
  )
  ```
- **Conflict:** **High.** The model is simultaneously told to be "Conversational and encouraging" (base prompt) and "XML-ONLY... NO prose" (appended).
  - *Risk:* Model may hallucinate polite conversational text *outside* the XML block, breaking the parser.

### Path C: Proposal Generation (Action editing)
- **Trigger:** `/propose` endpoint
- **Prompt Used:** `load_prompt("plan_proposal_generator")`
- **Construction:** Completely separate prompt. No base persona inheritance.
- **Reference:** `z:/Othello/utils/prompts.py` (Line 29). "You are Othello's Planning Engine... Return STRICT JSON only."
- **Status:** **Clean.** No persona conflict here.

### Path D: Daily Check-in / Reflection
- **Trigger:** `/checkin` -> `Fello.run_daily_check_in`
- **Prompt Used:** `generate_daily_prompt()` (Python function)
- **Construction:** Hardcoded string concatenation based on numeric mood score.
  - `tone = "üî• High energy detected..."`
  - `return f"{tone}\n\nüß† Reflective Prompt: {prompt}"`
- **Conflict:** **Medium.** The "Tone" is hardcoded in Python, bypassing the `life_architect` description. If the LLM's system prompt changes, this hardcoded tone will remain stale.

## 3. Consolidation Recommendations (No Code Changes)
1.  **Refactor Strict Planning:** Instead of appending to `life_architect`, create a dedicated `life_architect_planner` prompt that *duplicates* necessary context but *removes* the conversational instructions. This eliminates the "Be warm" vs "No prose" conflict.
2.  **Externalize Daily Tones:** Move the hardcoded Python strings ("üî•", "üåßÔ∏è") into `prompts.py` or `behavior.json` so they can be managed alongside the main persona.
3.  **Unified Greeting:** If a specific greeting is desired ("Hi there..."), it should be added to the `life_architect` prompt as a specific "Opening Rule" rather than relying on the model's training defaults.
